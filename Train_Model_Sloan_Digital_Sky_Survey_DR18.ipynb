{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dansah2/Sloan-Digital-Sky-Survey---DR18/blob/main/Train_Model_Sloan_Digital_Sky_Survey_DR18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hMxaRaUgS57"
      },
      "source": [
        "#Sloan Digital Sky Survey - DR18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmqXtL_Vgbef"
      },
      "source": [
        "This dataset consists of 100,000 observations from the Data Release (DR) 18 of the Sloan Digital Sky Survey (SDSS). Each observation is described by 42 features and 1 class column classifying the observation as either:\n",
        "\n",
        "a STAR\n",
        "a GALAXY\n",
        "a QSO (Quasi-Stellar Object) or a Quasar.\n",
        "\n",
        "Kaggle Dataset Download API Command:\n",
        "\n",
        "kaggle datasets download -d diraf0/sloan-digital-sky-survey-dr18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAto-d2mgoTQ"
      },
      "source": [
        "#Project Outline:\n",
        "1) Download the dataset\n",
        "\n",
        "2) Explore/Analyze the data\n",
        "\n",
        "3) Preprocess and organize the data for ML training\n",
        "\n",
        "4) Set appropriate weights\n",
        "\n",
        "5) Create and Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoMar6Krgpol"
      },
      "source": [
        "##Download / Read the Dataset\n",
        "1) Install required libraries\n",
        "\n",
        "2) Import required libraries\n",
        "\n",
        "3) Upload the data from Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLD_kjO7hS4O"
      },
      "source": [
        "###Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfp9GjQihRld",
        "outputId": "edc493e4-4e24-4b90-d888-352f7dc14e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.25.2 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.4/763.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U kaggle\n",
        "!pip install -q -U scikit-learn\n",
        "!pip install -q -U numpy\n",
        "!pip install -q -U torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYV_Hnw1hhQP"
      },
      "source": [
        "###Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SUK3SoSgnvS"
      },
      "outputs": [],
      "source": [
        "# handeling data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# graphing data\n",
        "pd.options.plotting.backend = \"plotly\"\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "# downloading data\n",
        "from google.colab import drive\n",
        "\n",
        "# splitting data\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# training the data\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchmetrics\n",
        "from torchmetrics import Accuracy\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Upload the data from Google Drive"
      ],
      "metadata": {
        "id": "2ckOx8jYrcKn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMX7vtdffTEV",
        "outputId": "08a24fe8-e08d-4ccb-e4f4-80c1cd4a04fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive to store Kaggle API for future use\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdasQl-fkmaL"
      },
      "outputs": [],
      "source": [
        "def read_function(csv_file):\n",
        "    return pd.read_csv(csv_file)\n",
        "\n",
        "raw_data = read_function('/content/drive/My Drive/NAME_OF_FOLDER/train_df.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LslL7TqKZeU1"
      },
      "source": [
        "## Create and Train model\n",
        "1) Set Device Agnostic Code\n",
        "\n",
        "2) Obtain the Class Weights\n",
        "\n",
        "3) Define the Focal Loss Function\n",
        "\n",
        "4) Define the Accuracy Function /Set Hyperparameters\n",
        "\n",
        "5) Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8XqzpiWLIZo"
      },
      "source": [
        "### Set Device Agnostic Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Vic6o58LLHY0",
        "outputId": "45ecb7dd-eeea-43b8-e92f-b44b1f9d0630"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAOa1henZygU"
      },
      "outputs": [],
      "source": [
        "# split the data and convert to tensor\n",
        "\n",
        "def split_return_tensor(data_frame, target):\n",
        "\n",
        "  # create X and y varialbles\n",
        "  y = data_frame[target]\n",
        "  X = data_frame.drop(columns=target)\n",
        "\n",
        "  # convert y into type int64\n",
        "  y = torch.tensor(y.values)\n",
        "  y = y.type(torch.LongTensor)\n",
        "\n",
        "  #convert X into type float32\n",
        "  X = torch.tensor(X.values)\n",
        "  X = X.type(torch.FloatTensor)\n",
        "\n",
        "  # convert X and y to a tensor dataset\n",
        "  tensor_data = torch.utils.data.TensorDataset(X, y)\n",
        "\n",
        "  # create the train and holding sizes\n",
        "  train_size = int(0.8 * len(tensor_data))\n",
        "  hold_size = len(tensor_data) - train_size\n",
        "\n",
        "  # create the training data\n",
        "  train_dataset, hold_dataset = random_split(tensor_data, [train_size, hold_size])\n",
        "\n",
        "  # create validation and testing sizes\n",
        "  valid_size = int(0.5 * len(hold_dataset))\n",
        "  test_size = len(hold_dataset) - valid_size\n",
        "\n",
        "  # create the validation and testing data\n",
        "  vaild_dataset, test_dataset = random_split(hold_dataset, [valid_size, test_size])\n",
        "\n",
        "  return train_dataset, vaild_dataset, test_dataset\n",
        "\n",
        "train_tensor, valid_tensor, test_tensor = split_return_tensor(raw_data, 'e_class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO9aVx91MnqP",
        "outputId": "2cb561d9-b8f4-48b5-ec43-ab41e733fcfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (linear_layer_stack): Sequential(\n",
              "    (0): Linear(in_features=42, out_features=8, bias=True)\n",
              "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=8, out_features=8, bias=True)\n",
              "    (5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.5, inplace=False)\n",
              "    (8): Linear(in_features=8, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, inputs, outputs, dropout_prob, hidden=8):\n",
        "    super().__init__()\n",
        "    self.linear_layer_stack = nn.Sequential(\n",
        "        nn.Linear(in_features=inputs, out_features=hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=dropout_prob),\n",
        "        nn.Linear(in_features=hidden, out_features=hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=dropout_prob),\n",
        "        nn.Linear(in_features=hidden, out_features=outputs)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear_layer_stack(x)\n",
        "\n",
        "input_num = 42\n",
        "output_num = 3\n",
        "\n",
        "model = Model(inputs=input_num,\n",
        "              outputs=output_num,\n",
        "              dropout_prob=0.5)\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxuqAwPqVKyk"
      },
      "source": [
        "###Obtain the Class Weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9CAHEjYUh_X"
      },
      "outputs": [],
      "source": [
        "def get_class_weights(data_frame, target):\n",
        "  # create X and y varialbles\n",
        "  y = data_frame[target]\n",
        "  X = data_frame.drop(columns=target)\n",
        "\n",
        "  # split the data\n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(X,\n",
        "                                                        y,\n",
        "                                                        test_size=0.2,\n",
        "                                                        shuffle=True)\n",
        "\n",
        "  class_counts = np.bincount(y_train)\n",
        "  num_classes = len(class_counts)\n",
        "  total_samples = len(y_train)\n",
        "\n",
        "  class_weights = []\n",
        "  for count in class_counts:\n",
        "      weight = 1 / (count / total_samples)\n",
        "      class_weights.append(weight)\n",
        "\n",
        "  return class_weights\n",
        "\n",
        "\n",
        "class_weights = get_class_weights(raw_data, 'e_class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPmZBCU2PTzy",
        "outputId": "83567640-915e-40ce-bcf3-7a0637648b37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.9119, 9.5602, 2.6856])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# convert list type to tensor\n",
        "class_weights = torch.Tensor(class_weights)\n",
        "class_weights.to(device)\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJD1qCQsWTpo"
      },
      "source": [
        "###Define the Focal Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0h2l134WRD4"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "  def __init__(self, alpha=None, gamma=2):\n",
        "      super(FocalLoss, self).__init__()\n",
        "      self.alpha = alpha\n",
        "      self.gamma = gamma\n",
        "\n",
        "      # Check if alpha is provided and if it's a tensor with non-zero values\n",
        "      if self.alpha is not None:\n",
        "          if not isinstance(self.alpha, torch.Tensor) or (self.alpha == 0).any():\n",
        "              raise ValueError(\"alpha should be a tensor with non-zero values for all classes.\")\n",
        "\n",
        "  def forward(self, inputs, targets):\n",
        "      ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "      ce_loss = torch.clamp(ce_loss, min=1e-10, max=1e10)\n",
        "      pt = torch.exp(-ce_loss) + 1e-10\n",
        "      loss = (self.alpha[targets] * (1 - pt) ** self.gamma * ce_loss).mean()\n",
        "      return loss\n",
        "\n",
        "loss_fn = FocalLoss(alpha=class_weights, gamma=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_dIw6piVQ_A"
      },
      "source": [
        "##Define the Accuracy Function /Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQEeBewrVZov"
      },
      "outputs": [],
      "source": [
        "# create the accuracy function\n",
        "accuracy = Accuracy(task='multiclass', num_classes=3)\n",
        "\n",
        "# set learning rate\n",
        "LR = 0.0001\n",
        "\n",
        "# create an optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id99brIbV9XF"
      },
      "source": [
        "##Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeh15TTpKlvj",
        "outputId": "b83b1bb7-ffec-4073-939e-f950be93373f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 accuracy: 0.52%\n",
            "Epoch 10 accuracy: 0.78%\n",
            "Epoch 20 accuracy: 0.78%\n",
            "Epoch 30 accuracy: 0.78%\n",
            "Epoch 40 accuracy: 0.78%\n",
            "Epoch 50 accuracy: 0.78%\n",
            "Epoch 60 accuracy: 0.78%\n",
            "Epoch 70 accuracy: 0.78%\n",
            "Epoch 80 accuracy: 0.78%\n",
            "Epoch 90 accuracy: 0.78%\n"
          ]
        }
      ],
      "source": [
        "# create the training method\n",
        "\n",
        "def train_model(model, tensor_train_data, tensor_valid_data, loss_fn, accuracy_fn, optimizer, device: torch.device = device):\n",
        "  # set number of epochs\n",
        "  EPOCHS = 100\n",
        "\n",
        "  # set manual seed\n",
        "  generator = torch.Generator()\n",
        "  generator.manual_seed(2022)\n",
        "\n",
        "  # put the data model and accuracy function on the desired device\n",
        "  model = model.to(device)\n",
        "  accuracy = accuracy_fn.to(device)\n",
        "  loss_fn = loss_fn.to(device)\n",
        "\n",
        "  # create the training and validation loaders\n",
        "  train_loader = torch.utils.data.DataLoader(tensor_train_data, batch_size=250, shuffle=True, generator=generator)\n",
        "  valid_loader = torch.utils.data.DataLoader(tensor_valid_data, batch_size=250)\n",
        "\n",
        "  #loop through the data\n",
        "  for epoch in range(EPOCHS):\n",
        "\n",
        "    # set model to train\n",
        "    model.train()\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "    for X_train, y_train in train_loader:\n",
        "      #put the data on the correct device\n",
        "      X_train = X_train.to(device)\n",
        "      y_train = y_train.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      y_logits = model(X_train)\n",
        "\n",
        "      # convert logits into probabilites then prediciton labels\n",
        "      y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
        "\n",
        "      # calculate the loss\n",
        "      loss = loss_fn(y_logits, y_train)\n",
        "\n",
        "      # optimizer zero_grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # back propagation\n",
        "      loss.backward()\n",
        "\n",
        "      # optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    ### Validation\n",
        "\n",
        "    # put model into eval and inference mode\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "\n",
        "      total_accuracy = 0\n",
        "\n",
        "      for X_valid, y_valid in valid_loader:\n",
        "\n",
        "        # create the valid logits\n",
        "        valid_logits = model(X_valid)\n",
        "\n",
        "        # convert logits into prediction proabailites then prediction labels\n",
        "        valid_preds = torch.softmax(valid_logits, dim=1).argmax(dim=1)\n",
        "\n",
        "        # calculate the loss\n",
        "        valid_loss = loss_fn(valid_logits, y_valid)\n",
        "\n",
        "        # calculate the accuracy\n",
        "        valid_acc = accuracy(valid_preds, y_valid)\n",
        "\n",
        "        # total accuracy\n",
        "        total_accuracy += valid_acc\n",
        "\n",
        "      epoch_accuracy = total_accuracy / len(valid_loader)\n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch} accuracy: {epoch_accuracy:.2f}%')\n",
        "\n",
        "  return model\n",
        "\n",
        "# call the training method\n",
        "model = train_model(model=model,\n",
        "                    tensor_train_data=train_tensor,\n",
        "                    tensor_valid_data=valid_tensor,\n",
        "                    loss_fn=loss_fn,\n",
        "                    accuracy_fn=accuracy,\n",
        "                    optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Save the model to Google Drive"
      ],
      "metadata": {
        "id": "o5hEU7Y1q7SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(model.state_dict(), '/content/drive/My Drive/NAME_OF_FOLDER/MODEL_NAME.pth')"
      ],
      "metadata": {
        "id": "uxjARp5Vq-cv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwnJVFjKe35/uUvhd1g1qm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}